{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transcriber (srt output).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8hok3pCMYM/2U5DauKMPP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanishque02/transcribing_using_deepspeech/blob/main/transcriber_(srt_output).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ej056UYouV0"
      },
      "outputs": [],
      "source": [
        "# Installing all the needed libraries\n",
        "!pip3 install deepspeech\n",
        "!pip install pytube\n",
        "!pip install pyAudioAnalysis\n",
        "!pip install eyed3\n",
        "!pip install pydub\n",
        "!pip install hmmlearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wave"
      ],
      "metadata": {
        "id": "-2MOnUJNsog0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the model and it's scorer file\n",
        "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm\n",
        "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer"
      ],
      "metadata": {
        "id": "ggjsA1phpEIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "import os\n",
        "def audio_video(url):\n",
        "  video = YouTube(url).streams.filter(progressive = True, res = '360p')\n",
        "  video_path = video.first().download()\n",
        "  os.rename(video_path, video_path.replace(' ', '-'))\n",
        "  new_video_path = video_path.replace(' ', '-')\n",
        "  audio_path = new_video_path.replace(\".mp4\", \"-audio.wav\")\n",
        "  extractAudio(new_video_path, audio_path)\n",
        "  return audio_path"
      ],
      "metadata": {
        "id": "wwz9yUw6pxx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyAudioAnalysis import audioBasicIO as aIO\n",
        "from pyAudioAnalysis import audioSegmentation as AS\n",
        "\n",
        "import scipy\n",
        "def silenceRemoval(input_file, smoothing_window = 1.0, weight = 0.2):\n",
        "    [fs, x] = aIO.read_audio_file(input_file)\n",
        "    segmentLimits = AS.silence_removal(x, fs, 0.05, 0.05, smoothing_window, weight)\n",
        "    segment_files = []\n",
        "    \n",
        "    for i, s in enumerate(segmentLimits):\n",
        "        strOut = \"{0:s}_{1:.3f}-{2:.3f}.wav\".format(input_file[0:-4], s[0], s[1])\n",
        "        scipy.io.wavfile.write(strOut, fs, x[int(fs * s[0]):int(fs * s[1])])\n",
        "        segment_files.append(strOut)\n",
        "      \n",
        "    return segment_files"
      ],
      "metadata": {
        "id": "z51jNiF7r1X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "def extractAudio(input_file, audio_file_name):\n",
        "    command = \"ffmpeg -hide_banner -loglevel warning -i {} -b:a 192k -ac 1 -ar 16000 -vn {}\".format(input_file, audio_file_name)\n",
        "    try:\n",
        "        ret = subprocess.call(command, shell=True)\n",
        "        print(\"Extracted audio to audio/{}\".format(audio_file_name.split(\"/\")[-1]))\n",
        "    except Exception as e:\n",
        "        print(\"Error: \", str(e))\n",
        "        exit(1)"
      ],
      "metadata": {
        "id": "KtWxt9Mcr5hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "def write_to_file(file_handle, inferred_text, line_count, limits):\n",
        "    \"\"\"Write the inferred text to SRT file\n",
        "    Follows a specific format for SRT files\n",
        "    Args:\n",
        "        file_handle : SRT file handle\n",
        "        inferred_text : text to be written\n",
        "        line_count : subtitle line count \n",
        "        limits : starting and ending times for text\n",
        "    \"\"\"\n",
        "    \n",
        "    d = str(datetime.timedelta(seconds=float(limits[0])))\n",
        "    try:\n",
        "        from_dur = \"0\" + str(d.split(\".\")[0]) + \",\" + str(d.split(\".\")[-1][:2])\n",
        "    except:\n",
        "        from_dur = \"0\" + str(d) + \",\" + \"00\"\n",
        "        \n",
        "    d = str(datetime.timedelta(seconds=float(limits[1])))\n",
        "    try:\n",
        "        to_dur = \"0\" + str(d.split(\".\")[0]) + \",\" + str(d.split(\".\")[-1][:2])\n",
        "    except:\n",
        "        to_dur = \"0\" + str(d) + \",\" + \"00\"\n",
        "        \n",
        "    with open(file_handle, 'a') as f:\n",
        "      f.write(str(line_count) + \"\\n\")\n",
        "      f.write(from_dur + \" --> \" + to_dur + \"\\n\")\n",
        "      f.write(inferred_text + \"\\n\\n\")"
      ],
      "metadata": {
        "id": "sG1R5gGZsESP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from deepspeech import Model \n",
        "\n",
        "def ds_process_audio(audio_file): \n",
        "    ds = Model(\"/content/deepspeech-0.9.3-models.pbmm\")\n",
        "    ds.enableExternalScorer(\"/content/deepspeech-0.9.3-models.scorer\")\n",
        "    \n",
        "    fin = wave.open(audio_file, 'rb')\n",
        "    audio = np.frombuffer(fin.readframes(fin.getnframes()), np.int16)\n",
        "    fin.close()\n",
        "    \n",
        "    # Perform inference on audio segment\n",
        "    infered_text = ds.stt(audio)\n",
        "    \n",
        "    # File name contains start and end times in seconds. Extract that\n",
        "    limits = audio_file.split(\"/\")[-1][:-4].split(\"_\")[-1].split(\"-\")\n",
        "\n",
        "    return infered_text, limits"
      ],
      "metadata": {
        "id": "zJ8GH10mvrfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe(url):\n",
        "  audio_path = audio_video(url)\n",
        "  segment_files = silenceRemoval(audio_path)\n",
        "\n",
        "  line_count = 1\n",
        "  for i in segment_files:\n",
        "    infered_text, limits = ds_process_audio(i)\n",
        "    if len(infered_text) !=0:\n",
        "      write_to_file(\"srt.srt\", infered_text, line_count, limits)\n",
        "      line_count += 1"
      ],
      "metadata": {
        "id": "tFCfWemCvAy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcribe(url)"
      ],
      "metadata": {
        "id": "lhqs943J5pNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MjMrzNmq6Owl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}